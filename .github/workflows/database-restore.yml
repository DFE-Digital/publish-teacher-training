name: Database Backup and Restore

on:
  schedule: # 01:00 UTC
    - cron: "0 1 * * *"
  workflow_dispatch:
    inputs:
      environment:
        description: Environment to backup. No sanitised backup or restore will occur.
        required: true
        default: qa
        type: choice
        options:
          - qa
          - staging
          - sandbox
          - production
      backup-file:
        description: |
          Backup file name (without extension). Default is ptt_[env]_adhoc_YYYY-MM-DD. Set it explicitly when backing up a point-in-time (PTR) server. (Optional)
        required: false
        type: string
        default: default
      db-server:
        description: |
          Name of the database server. Default is the live server. When backing up a point-in-time (PTR) server, use the full name of the PTR server. (Optional)

env:
  SERVICE_NAME: publish
  SERVICE_SHORT: ptt
  TF_VARS_PATH: terraform/aks/workspace_variables

permissions:
  id-token: write

jobs:
  backup:
    name: Database Backup
    runs-on: ubuntu-latest
    environment:
      name: ${{ inputs.environment || 'production' }}
    env:
      DEPLOY_ENV: ${{ inputs.environment || 'production'  }}
      BACKUP_FILE: ${{ inputs.backup-file || 'schedule'  }}
    services:
      postgres:
        image: postgres:14.7
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: postgres
        ports:
          - 5432:5432
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set KV environment variables
        run: |
          source global_config/${DEPLOY_ENV}.sh
          tf_vars_file=${TF_VARS_PATH}/${DEPLOY_ENV}.tfvars.json
          echo "key_vault_name=$(jq -r '.key_vault_name' ${tf_vars_file})" >> $GITHUB_ENV
          echo "NAMESPACE=$(jq -r '.namespace' ${tf_vars_file})" >> $GITHUB_ENV
          echo "CLUSTER=$(jq -r '.cluster' ${tf_vars_file})" >> $GITHUB_ENV
          echo "RESOURCE_GROUP_NAME=${RESOURCE_NAME_PREFIX}-${SERVICE_SHORT}-${CONFIG_SHORT}-rg" >> $GITHUB_ENV
          echo "STORAGE_ACCOUNT_NAME=${RESOURCE_NAME_PREFIX}${SERVICE_SHORT}dbbkp${CONFIG_SHORT}sa" >> $GITHUB_ENV
          TODAY=$(date +"%F")
          echo "DB_SERVER=${RESOURCE_NAME_PREFIX}-${SERVICE_SHORT}-${CONFIG_SHORT}-psql" >> $GITHUB_ENV
          if [ "${BACKUP_FILE}" == "schedule" ]; then
            BACKUP_FILE=${SERVICE_SHORT}_${CONFIG_SHORT}_${TODAY}
          elif [ "${BACKUP_FILE}" == "default" ]; then
            BACKUP_FILE=${SERVICE_SHORT}_${CONFIG_SHORT}_adhoc_${TODAY}
          else
            BACKUP_FILE=${BACKUP_FILE}
          fi
          echo "BACKUP_FILE=${BACKUP_FILE}" >> $GITHUB_ENV

      - name: Backup ${{ env.DEPLOY_ENV }} postgres
        uses: DFE-Digital/github-actions/backup-postgres@master
        with:
          storage-account: ${{ env.STORAGE_ACCOUNT_NAME }}
          resource-group: ${{ env.RESOURCE_GROUP_NAME }}
          app-name: ${{ env.SERVICE_NAME }}-${{ env.DEPLOY_ENV }}
          namespace: ${{ env.NAMESPACE }}
          cluster: ${{ env.CLUSTER }}
          azure-client-id: ${{ secrets.AZURE_CLIENT_ID }}
          azure-tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          azure-subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          backup-file: ${{ env.BACKUP_FILE }}.sql
          db-server-name: ${{ inputs.db-server }}
          slack-webhook: ${{ secrets.SLACK_WEBHOOK }}

      - name: Set env variable
        if: github.event_name == 'schedule'
        run: echo "SANITISED_FILE_NAME=publish_sanitised_$(date +"%F")" >> $GITHUB_ENV

      - name: Sanitise the Database backup
        if: github.event_name == 'schedule'
        run: |
          echo "::group::Restore backup to intermediate database"
          createdb ${DATABASE_NAME} && gzip -d --to-stdout ${{ env.BACKUP_FILE }}.sql.gz | psql -d ${DATABASE_NAME}
          echo "::endgroup::"

          echo "::group::Clear user data"
          psql -d ${DATABASE_NAME} -f db/scripts/sanitise.sql
          echo "::endgroup::"

          echo "::group::Integration setup"
          psql -d ${DATABASE_NAME} -f db/scripts/integration_setup.sql
          echo "::endgroup::"

          echo "::debug::Remove ${{ env.BACKUP_FILE }}.sql.gz"
          rm ${{ env.BACKUP_FILE }}.sql.gz

          echo "::group::Backup Sanitised Database"
          pg_dump --compress=1 --encoding utf8 --clean --no-owner --if-exists -d ${DATABASE_NAME} -f ${SANITISED_FILE_NAME}.sql.gz
          echo "::endgroup::"
        env:
          DATABASE_NAME: teacher_training_api
          PGUSER: postgres
          PGPASSWORD: postgres
          PGHOST: localhost
          PGPORT: 5432

      - name: Upload Backup to Azure Storage
        if: github.event_name == 'schedule'
        run: |
          az storage blob upload --container-name database-backup \
          --file ${SANITISED_FILE_NAME}.sql.gz --name ${SANITISED_FILE_NAME}.sql.gz --overwrite \
          --connection-string '${{ secrets.AZURE_STORAGE_CONNECTION_STRING_SANITISED }}'
          rm ${SANITISED_FILE_NAME}.sql.gz

  restore:
    needs: [backup]
    if: github.event_name == 'schedule'
    runs-on: ubuntu-latest
    environment:
      name: ${{ matrix.environment }}
    env:
      GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    strategy:
      fail-fast: false
      matrix:
        environment: [qa, staging]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Restore database
        id: restore
        uses: ./.github/actions/restore/
        with:
          azure-tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          azure-subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          azure-client-id: ${{ secrets.AZURE_CLIENT_ID }}
          azure-storage-connection-string: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING_SANITISED }}
          environment: ${{ matrix.environment }}
